{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#legacy code that was used to scrape cuspajz.com before switching to tekstovi.net as main songbase\n",
    "import pandas as pd\n",
    "import base64\n",
    "import os\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "## Create empty df:\n",
    "column_names = [\"Artist\", \"ArtistDiskografija\", \"Song_ID\", \"Song\", \"Lyrics\", \"Url\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping cuspajz.com for song lyrics by artist (change url to change artist)\n",
    "\n",
    "# Based on:\n",
    "#    https://www.dataquest.io/blog/web-scraping-beautifulsoup/\n",
    "#    https://github.com/aakashbansal/Songs-Lyrics-Web-Scraper/blob/master/Lyrics%20Scraper.ipynb\n",
    "\n",
    "artist = 'Severina'\n",
    "diskografija_artist_name = 'Severina'\n",
    "# artist url\n",
    "url = 'https://cuspajz.com/tekstovi-pjesama/izvodjac/severina.html'\n",
    "\n",
    "# generate random artist ID and make sure it doesnt have '_'\n",
    "artist_ID = base64.b64encode(os.urandom(6)).decode('ascii')\n",
    "while(artist_ID.find('_')>=0):\n",
    "    artist_ID = base64.b64encode(os.urandom(6)).decode('ascii')\n",
    "    \n",
    "delay = 2\n",
    "\n",
    "response = get(url)\n",
    "# print(response.text[:500])\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# print(type(html_soup))\n",
    "\n",
    "\n",
    "# Get the list of songs\n",
    "songs = html_soup.find_all('ul', class_='songList')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_index, column in enumerate(songs):\n",
    "    songs = column.find_all('li')\n",
    "\n",
    "    for index, song in enumerate(songs):\n",
    "\n",
    "        song_name = song.a.text\n",
    "        song_url = song.a['href']\n",
    "\n",
    "        url = 'https://cuspajz.com/'+song_url\n",
    "\n",
    "        response = get(url)\n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        song_lyrics = html_soup.find_all('p', class_='clearfix')\n",
    "        lyrics =  song_lyrics[0].get_text()\n",
    "            \n",
    "        song_ID = artist_ID + '_' + str(1) + '_' + str(index)  \n",
    "\n",
    "        new_entry = pd.DataFrame([[artist, diskografija_artist_name, song_name, song_ID, lyrics, url]], columns=[\"Artist\", \"ArtistDiskografija\", \"Song\", \"Song_ID\", \"Lyrics\", \"Url\"])\n",
    "        df = df.append(new_entry, ignore_index=True)\n",
    "\n",
    "        print(\"Lyrics successfully written to file for : \" + song_name)\n",
    "                      \n",
    "        sleep(delay)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'data/{artist}_cuspajz.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
